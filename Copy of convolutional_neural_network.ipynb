{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of convolutional_neural_network.ipynb","provenance":[{"file_id":"1Y-a4g98w93GHswXLRLoiogvMYNPgzPE9","timestamp":1594159927036}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"3DR-eO17geWu","colab_type":"text"},"source":["# Convolutional Neural Network"]},{"cell_type":"markdown","metadata":{"id":"hWuSHCA4Wj_6","colab_type":"text"},"source":["We are importing the keras library to import a specific class from the library. This library was developed my facebook. "]},{"cell_type":"markdown","metadata":{"id":"v_iKwqo9XXPG","colab_type":"text"},"source":["# Importing Libraries "]},{"cell_type":"code","metadata":{"id":"pugHTAe4WV25","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1594400177706,"user_tz":300,"elapsed":6065,"user":{"displayName":"Saxton Randle-Sims","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSDotnX0MxQTjCDKQe4Tsfs2iH45uRAovpepY7w=s64","userId":"02874804793914908133"}},"outputId":"798350c2-0bac-4807-ef8a-5e0b4e82f812"},"source":["import tensorflow as tf  \n","from keras.preprocessing.image import ImageDataGenerator  \n","import os"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"KmMm6KUxhOPC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1594247053404,"user_tz":300,"elapsed":674,"user":{"displayName":"Saxton Randle-Sims","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSDotnX0MxQTjCDKQe4Tsfs2iH45uRAovpepY7w=s64","userId":"02874804793914908133"}},"outputId":"b74417d4-1f17-4895-8dd9-d31757ff8f8c"},"source":["cwd = os.getcwd() \n","files = os.listdir(cwd)  # Get all the files in that directory\n","print(\"Files in %r: %s\" % (cwd, files))"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Files in '/content': ['.config', 'sample_data']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tnd50jcaheq9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1594246960837,"user_tz":300,"elapsed":691,"user":{"displayName":"Saxton Randle-Sims","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSDotnX0MxQTjCDKQe4Tsfs2iH45uRAovpepY7w=s64","userId":"02874804793914908133"}},"outputId":"535b94fd-28aa-4023-cd8d-21f1e84a5c9a"},"source":["print(cwd)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["/content\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"v5zsKzUOjw2R","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":186},"executionInfo":{"status":"error","timestamp":1594247612946,"user_tz":300,"elapsed":719,"user":{"displayName":"Saxton Randle-Sims","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSDotnX0MxQTjCDKQe4Tsfs2iH45uRAovpepY7w=s64","userId":"02874804793914908133"}},"outputId":"7e4e20a0-097a-4701-c6c2-ba62b79b7dd3"},"source":["f = open(\"Users/Saxton Randle-Sims/Desktop/Section 40 - Convolutional Neural Networks (CNN)/dataset/training_set\")"],"execution_count":24,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-1b252c5e62ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Users/Saxton Randle-Sims/Desktop/Section 40 - Convolutional Neural Networks (CNN)/dataset/training_set\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Users/Saxton Randle-Sims/Desktop/Section 40 - Convolutional Neural Networks (CNN)/dataset/training_set'"]}]},{"cell_type":"code","metadata":{"id":"wVOeLLCjXBs0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1594246491219,"user_tz":300,"elapsed":638,"user":{"displayName":"Saxton Randle-Sims","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSDotnX0MxQTjCDKQe4Tsfs2iH45uRAovpepY7w=s64","userId":"02874804793914908133"}},"outputId":"d8cd832a-8048-4616-821b-4df13ee6488f"},"source":["tf.__version__"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic":{"type":"string"},"text/plain":["'2.2.0'"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"oxQxCBWyoGPE","colab_type":"text"},"source":["## Part 1 - Data Preprocessing"]},{"cell_type":"markdown","metadata":{"id":"6wk-kJnlXm3A","colab_type":"text"},"source":["Here we're going to transform the pictures. This is called \"image augmentations\" basically augmenting the variety of the pictures and creating new pictures. Used the keras library to pull the right syntax to train the training set preprocessing "]},{"cell_type":"markdown","metadata":{"id":"MvE-heJNo3GG","colab_type":"text"},"source":["### Preprocessing the Training set"]},{"cell_type":"code","metadata":{"id":"M48C1cDgY40b","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":366},"executionInfo":{"status":"error","timestamp":1594400743976,"user_tz":300,"elapsed":3410,"user":{"displayName":"Saxton Randle-Sims","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSDotnX0MxQTjCDKQe4Tsfs2iH45uRAovpepY7w=s64","userId":"02874804793914908133"}},"outputId":"33f3dae7-7032-4891-ca44-d8da955f0f9f"},"source":["train_datagen = ImageDataGenerator(\n","        rescale=1./255,\n","        shear_range=0.2,\n","        zoom_range=0.2,\n","        horizontal_flip=True) \n","training_set = train_datagen.flow_from_directory(\n","        'dataset/training_set',\n","        target_size=(64, 64),\n","        batch_size=32, \n","        class_mode='binary')"],"execution_count":4,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-d1f4c7ec4bce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         class_mode='binary')\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation)\u001b[0m\n\u001b[1;32m    465\u001b[0m             \u001b[0mfollow_links\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_links\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m             \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m         )\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m             dtype=dtype)\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/directory_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset/training_set'"]}]},{"cell_type":"markdown","metadata":{"id":"mrCMmGw9pHys","colab_type":"text"},"source":["### Preprocessing the Test set"]},{"cell_type":"markdown","metadata":{"id":"X04CxdOebO_R","colab_type":"text"},"source":["Now it's time to preprocess the test set for your images. "]},{"cell_type":"code","metadata":{"id":"-wVeQzGGZ4Ob","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":366},"executionInfo":{"status":"error","timestamp":1594246533893,"user_tz":300,"elapsed":645,"user":{"displayName":"Saxton Randle-Sims","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSDotnX0MxQTjCDKQe4Tsfs2iH45uRAovpepY7w=s64","userId":"02874804793914908133"}},"outputId":"31a8a0fc-21a1-4d46-bc8c-2e52e775fdaf"},"source":["test_datagen = ImageDataGenerator(rescale=1./255) \n","test_set = test_datagen.flow_from_directory(\n","        'dataset/test_set',\n","        target_size=(64, 64),\n","        batch_size=32,\n","        class_mode='binary')"],"execution_count":11,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-eaf8f800aa5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         class_mode='binary')\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation)\u001b[0m\n\u001b[1;32m    465\u001b[0m             \u001b[0mfollow_links\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_links\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m             \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m         )\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m             dtype=dtype)\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/directory_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset/test_set'"]}]},{"cell_type":"markdown","metadata":{"id":"af8O4l90gk7B","colab_type":"text"},"source":["## Part 2 - Building the CNN"]},{"cell_type":"markdown","metadata":{"id":"8naq8ZkDbbNo","colab_type":"text"},"source":["We want to build the archictecture for our ANN. We want to call the sequential method which will allow us to build our first layer. "]},{"cell_type":"markdown","metadata":{"id":"ces1gXY2lmoX","colab_type":"text"},"source":["### Initialising the CNN"]},{"cell_type":"code","metadata":{"id":"xGJFvuyhbism","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1594244823559,"user_tz":300,"elapsed":2600,"user":{"displayName":"Saxton Randle-Sims","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSDotnX0MxQTjCDKQe4Tsfs2iH45uRAovpepY7w=s64","userId":"02874804793914908133"}}},"source":["cnn = tf.keras.models.Sequential"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u5YJj_XMl5LF","colab_type":"text"},"source":["### Step 1 - Convolution"]},{"cell_type":"markdown","metadata":{"id":"l6QBChGMfYgs","colab_type":"text"},"source":["Basically, what's happening here is that we are building our first layer of the CNN architecture (the brain) and we are using a specific class function and parameters to help us formalize out data "]},{"cell_type":"code","metadata":{"id":"akeQiMmvb0LV","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1594244823561,"user_tz":300,"elapsed":2594,"user":{"displayName":"Saxton Randle-Sims","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSDotnX0MxQTjCDKQe4Tsfs2iH45uRAovpepY7w=s64","userId":"02874804793914908133"}}},"source":["cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64,64,3]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tf87FpvxmNOJ","colab_type":"text"},"source":["### Step 2 - Pooling"]},{"cell_type":"markdown","metadata":{"id":"K-cEUQUThK3b","colab_type":"text"},"source":["The syntax below can be used to provide max pulling to any of your CNN models "]},{"cell_type":"code","metadata":{"id":"2eMLVAz3frbD","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1594244823563,"user_tz":300,"elapsed":2587,"user":{"displayName":"Saxton Randle-Sims","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSDotnX0MxQTjCDKQe4Tsfs2iH45uRAovpepY7w=s64","userId":"02874804793914908133"}}},"source":["cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xaTOgD8rm4mU","colab_type":"text"},"source":["### Adding a second convolutional layer"]},{"cell_type":"code","metadata":{"id":"wHr_l116hWpP","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1594244823565,"user_tz":300,"elapsed":2578,"user":{"displayName":"Saxton Randle-Sims","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSDotnX0MxQTjCDKQe4Tsfs2iH45uRAovpepY7w=s64","userId":"02874804793914908133"}}},"source":["cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n","cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tmiEuvTunKfk","colab_type":"text"},"source":["### Step 3 - Flattening"]},{"cell_type":"code","metadata":{"id":"OHG6vs5eiK2R","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1594244823566,"user_tz":300,"elapsed":2554,"user":{"displayName":"Saxton Randle-Sims","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSDotnX0MxQTjCDKQe4Tsfs2iH45uRAovpepY7w=s64","userId":"02874804793914908133"}}},"source":["cnn.add(tf.keras.layers.Flatten)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dAoSECOm203v","colab_type":"text"},"source":["### Step 4 - Full Connection"]},{"cell_type":"code","metadata":{"id":"qqyaeQdDiobZ","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1594244823568,"user_tz":300,"elapsed":2543,"user":{"displayName":"Saxton Randle-Sims","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSDotnX0MxQTjCDKQe4Tsfs2iH45uRAovpepY7w=s64","userId":"02874804793914908133"}}},"source":["cnn.add(tf.keras.layers.Dense(units=128, activation= 'relu',))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yTldFvbX28Na","colab_type":"text"},"source":["### Step 5 - Output Layer"]},{"cell_type":"markdown","metadata":{"id":"bM9bMbwVjLd7","colab_type":"text"},"source":["Need to change units to 1 because you're predicting a binary classification either \"dog or cat\" and change the activiation to \"sigmoid\" because of the binary classification but if it was multiple classifcation then you would change it to soft max activation"]},{"cell_type":"code","metadata":{"id":"z3lG62NkjBNM","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1594244823570,"user_tz":300,"elapsed":2539,"user":{"displayName":"Saxton Randle-Sims","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSDotnX0MxQTjCDKQe4Tsfs2iH45uRAovpepY7w=s64","userId":"02874804793914908133"}}},"source":["cnn.add(tf.keras.layers.Dense(units=1, activation= 'sigmoid',))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D6XkI90snSDl","colab_type":"text"},"source":["## Part 3 - Training the CNN"]},{"cell_type":"markdown","metadata":{"id":"vfrFQACEnc6i","colab_type":"text"},"source":["### Compiling the CNN"]},{"cell_type":"code","metadata":{"id":"F2IY3zFVkXv9","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1594244823571,"user_tz":300,"elapsed":2525,"user":{"displayName":"Saxton Randle-Sims","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSDotnX0MxQTjCDKQe4Tsfs2iH45uRAovpepY7w=s64","userId":"02874804793914908133"}}},"source":["cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy' , metrics = ['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ehS-v3MIpX2h","colab_type":"text"},"source":["### Training the CNN on the Training set and evaluating it on the Test set"]},{"cell_type":"markdown","metadata":{"id":"6bINy-a8m4cT","colab_type":"text"},"source":["fit method always train the model on the training set "]},{"cell_type":"code","metadata":{"id":"Fn-lVeRYk0Ti","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1594244823573,"user_tz":300,"elapsed":2519,"user":{"displayName":"Saxton Randle-Sims","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSDotnX0MxQTjCDKQe4Tsfs2iH45uRAovpepY7w=s64","userId":"02874804793914908133"}}},"source":["cnn.fit(x = Training_set, validation_data = Test_set, epochs = 25)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U3PZasO0006Z","colab_type":"text"},"source":["## Part 4 - Making a single prediction"]},{"cell_type":"markdown","metadata":{"id":"VTKJSQKqpo1v","colab_type":"text"},"source":["You can find the syntax for these functions in https://keras.io/api/preprocessing/image/#imagedatagenerator-class"]},{"cell_type":"code","metadata":{"id":"8TXiKOPbn-xh","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1594244823574,"user_tz":300,"elapsed":2509,"user":{"displayName":"Saxton Randle-Sims","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSDotnX0MxQTjCDKQe4Tsfs2iH45uRAovpepY7w=s64","userId":"02874804793914908133"}}},"source":["import numpy as np\n","from keras_preprocessing import image\n","test_image = image.load.img(('dataset/single_prediction/cat_or_dog_1.jpg', target_size = (64, 64))) \n","test_image = image.img_to_array(test_image) \n","test_image = np.expand_dime(test_image, axis= 0)\n","result = cnn.predict(test_shape) \n","training_set.class_indices  \n","if results[0][0] == 1:\n","  prediction = 'dog' \n","else: \n","  prediction = 'cat' \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5jidBWU4Td6Y","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1594244823576,"user_tz":300,"elapsed":2495,"user":{"displayName":"Saxton Randle-Sims","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDSDotnX0MxQTjCDKQe4Tsfs2iH45uRAovpepY7w=s64","userId":"02874804793914908133"}}},"source":["print(prediction)"],"execution_count":null,"outputs":[]}]}